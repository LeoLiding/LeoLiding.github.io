import threading
import time
import base64
import mimetypes
import os
from openai import OpenAI
import tiktoken  # ç”¨äºè®¡ç®— token æ•°é‡
import msvcrt  # Windows ä¸“ç”¨
import sounddevice as sd
from scipy.io.wavfile import write, read
from datetime import datetime
import json
import uuid
import traceback
import numpy as np
from pydub import AudioSegment  # æ·»åŠ éŸ³é¢‘å¤„ç†åº“

# åˆ›å»ºå¿…è¦çš„æ–‡ä»¶å¤¹
def ensure_directories():
    # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
    current_dir = os.path.dirname(os.path.abspath(__file__))
    # åˆ›å»º audio å’Œ log æ–‡ä»¶å¤¹
    audio_dir = os.path.join(current_dir, "audio")
    log_dir = os.path.join(current_dir, "log")
    os.makedirs(audio_dir, exist_ok=True)
    os.makedirs(log_dir, exist_ok=True)
    return audio_dir, log_dir

# åˆå§‹åŒ–æ–‡ä»¶å¤¹
AUDIO_DIR, LOG_DIR = ensure_directories()

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = OpenAI(
    api_key="token-abc123",
    base_url="http://183.11.229.111:8048/v1"
)

# æ‰“æ–­äº‹ä»¶ç›‘å¬
stop_event = threading.Event()

def compress_audio(input_path, max_size_mb=30):
    """å‹ç¼©éŸ³é¢‘æ–‡ä»¶ï¼Œç¡®ä¿å¤§å°ä¸è¶…è¿‡æŒ‡å®šé™åˆ¶"""
    try:
        audio = AudioSegment.from_wav(input_path)
        original_size = os.path.getsize(input_path) / (1024 * 1024)  # è½¬æ¢ä¸ºMB
        
        if original_size <= max_size_mb:
            return input_path
            
        # è®¡ç®—éœ€è¦çš„å‹ç¼©æ¯”ä¾‹
        compression_ratio = max_size_mb / original_size
        
        # é™ä½é‡‡æ ·ç‡ï¼ˆæœ€å°åˆ°8kHzï¼‰
        target_sample_rate = max(8000, int(audio.frame_rate * compression_ratio))
        audio = audio.set_frame_rate(target_sample_rate)
        
        # è½¬æ¢ä¸ºå•å£°é“
        audio = audio.set_channels(1)
        
        # ä¿å­˜å‹ç¼©åçš„éŸ³é¢‘
        compressed_path = input_path.replace('.wav', '_compressed.wav')
        audio.export(compressed_path, format='wav')
        
        compressed_size = os.path.getsize(compressed_path) / (1024 * 1024)
        print(f"ğŸ“Š éŸ³é¢‘å‹ç¼©ï¼š{original_size:.1f}MB -> {compressed_size:.1f}MB")
        
        return compressed_path
    except Exception as e:
        print(f"âš ï¸ éŸ³é¢‘å‹ç¼©å¤±è´¥ï¼š{str(e)}")
        return input_path

# å½•éŸ³å‡½æ•°
def record_audio(filename=None, fs=16000):
    if filename is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"recorded_audio.wav"
    # ç¡®ä¿æ–‡ä»¶ååœ¨ audio ç›®å½•ä¸‹
    filepath = os.path.join(AUDIO_DIR, filename)
    
    print(f"ğŸ™ï¸ æŒ‰ä½ç©ºæ ¼é”®å¼€å§‹å½•éŸ³ï¼Œæ¾å¼€ç»“æŸå½•éŸ³...")
    print(f"âš ï¸ æ³¨æ„ï¼šå½•éŸ³æ–‡ä»¶å¤§å°è¯·ä¸è¦è¶…è¿‡30MB")
    
    # ç­‰å¾…ç©ºæ ¼é”®æŒ‰ä¸‹
    while True:
        if msvcrt.kbhit():
            key = msvcrt.getch()
            if key == b' ':  # ç©ºæ ¼é”®
                break
        time.sleep(0.1)
    
    # å¼€å§‹å½•éŸ³
    recording = []
    print("ğŸ™ï¸ å¼€å§‹å½•éŸ³...")
    
    # åˆ›å»ºå½•éŸ³æµ
    with sd.InputStream(samplerate=fs, channels=1, dtype='int16') as stream:
        while True:
            if msvcrt.kbhit():
                key = msvcrt.getch()
                if key == b' ':  # å¦‚æœç©ºæ ¼é”®è¢«æ¾å¼€
                    break
            audio_chunk, _ = stream.read(1024)
            recording.append(audio_chunk)
    
    # åˆå¹¶å½•éŸ³æ•°æ®
    recording = np.concatenate(recording, axis=0)
    
    # ä¿å­˜å½•éŸ³
    write(filepath, fs, recording)
    
    # å‹ç¼©éŸ³é¢‘
    compressed_path = compress_audio(filepath)
    print(f"âœ… å½•éŸ³å®Œæˆï¼Œä¿å­˜ä¸ºï¼š{compressed_path}")
    return compressed_path

# æ‰“æ–­ç›‘å¬å™¨
def interrupt_listener():
    print("\nâ³ æç¤ºï¼šæŒ‰ä»»æ„é”®æ‰“æ–­è¾“å‡º...\n")
    while not stop_event.is_set():
        if msvcrt.kbhit():
            msvcrt.getch()
            stop_event.set()
            print("\nğŸ›‘ æ‰‹åŠ¨æ‰“æ–­å“åº”ï¼\n")
            break
        time.sleep(0.1)

# æ–‡ä»¶è½¬ base64 + MIME ç±»å‹
def file_to_data_url(file_path):
    with open(file_path, 'rb') as f:
        base64_data = base64.b64encode(f.read()).decode('utf-8')
    mime_type, _ = mimetypes.guess_type(file_path)
    mime_type = mime_type or "application/octet-stream"
    return f"data:{mime_type};base64,{base64_data}"

# åˆå§‹åŒ–å¯¹è¯å†å²
messages = [
    {
        "role": "system",
        "content": """ä½ æ˜¯ä¸€ä¸ªå’Œæˆ‘å¯¹è¯çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œè¯·ä½¿ç”¨æ¸©æš–ã€äº²åˆ‡çš„è¯­æ°”å’Œæˆ‘äº¤æµï¼Œå¸®æˆ‘ç–è§£æˆ‘çš„å¿ƒç†ã€‚
"""
            }
        ]
#"content": "ä½ æ˜¯ä¸€ä¸ªå’Œæˆ‘å¯¹è¯çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œè¯·ä½¿ç”¨æ¸©æš–ã€äº²åˆ‡çš„è¯­æ°”å’Œæˆ‘äº¤æµï¼Œå¸®æˆ‘ç–è§£æˆ‘çš„å¿ƒç†ã€‚å¹¶åœ¨æ¯æ¬¡è¾“å‡ºæ—¶ï¼Œå°†æˆ‘è¾“å…¥çš„éŸ³é¢‘è½¬æˆæ–‡æœ¬ä¸€èµ·è¾“å‡ºã€‚"
#ç»Ÿè®¡ messages çš„æ€» token æ•°
def count_tokens(messages, model="gpt-3.5-turbo"):  # å…¼å®¹ OpenAI æ ¼å¼
    enc = tiktoken.encoding_for_model(model)
    tokens_per_message = 3  # æ¯æ¡æ¶ˆæ¯çš„é¢å¤–tokenï¼ˆOpenAIå‡è®¾ï¼‰
    tokens_per_name = 1     # å¦‚æœå­˜åœ¨nameå­—æ®µ

    num_tokens = 0
    for message in messages:
        num_tokens += tokens_per_message
        for key, value in message.items():
            if key == "content":
                if isinstance(value, list):  # æ”¯æŒéŸ³é¢‘ç»“æ„
                    for item in value:
                        if item["type"] == "text":
                            num_tokens += len(enc.encode(item["text"]))
                        elif item["type"] == "audio_url":
                            # éŸ³é¢‘ç»“æ„ä¸ç®—å…¥ tokenï¼Œæˆ–ç•¥ä¼°ä¸€ä¸ªé•¿åº¦
                            num_tokens += 5
                elif isinstance(value, str):
                    num_tokens += len(enc.encode(value))
            elif key == "role":
                num_tokens += len(enc.encode(value))
            elif key == "name":
                num_tokens += tokens_per_name + len(enc.encode(value))
    return num_tokens + 3  # æœ€åçš„ reply æ¶ˆæ¯çš„ priming tokens

# ä¿å­˜å¯¹è¯å†å²åˆ°æ–‡ä»¶
def save_conversation_history(messages, filename=None):
    if filename is None:
        # ä½¿ç”¨å½“å‰æ—¶é—´åˆ›å»ºæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"conversation_history_{timestamp}.txt"
    
    # ç¡®ä¿æ–‡ä»¶ååœ¨ log ç›®å½•ä¸‹
    filepath = os.path.join(LOG_DIR, filename)
    
    with open(filepath, "w", encoding="utf-8") as f:
        # å°†messagesåˆ—è¡¨è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²ï¼Œç¡®ä¿ä¸­æ–‡æ­£ç¡®æ˜¾ç¤º
        json_str = json.dumps(messages, ensure_ascii=False, indent=2)
        f.write(json_str)
    print(f"\nğŸ’¾ å¯¹è¯å†å²å·²ä¿å­˜åˆ°ï¼š{filepath}")
    return filepath

# ä¸»æµç¨‹ï¼ˆæ”¯æŒå¤šè½®ï¼‰
def run_minicpm_stream():
    round_count = 1
    conversation_file = None
    while True:
        print(f"\nğŸ—£ï¸ ç¬¬ {round_count} è½®å¯¹è¯")

        # æ‰“å°å†å²å¯¹è¯è®°å½•
        print("\nğŸ“œ å†å²æ¶ˆæ¯é˜Ÿåˆ—ï¼š")
        for i, msg in enumerate(messages):
            role = "ğŸ‘¤ ç”¨æˆ·     " if msg["role"] == "user" else ("ğŸ¤– Minicpm-o" if msg["role"] == "assistant" else "âš™ï¸  ç³»ç»Ÿ     ")
            content = msg["content"]
            if isinstance(content, list):
                content_str = ""
                for item in content:
                    if item["type"] == "text":
                        content_str += item["text"]
                    elif item["type"] == "audio_url":
                        raw = str(item)[:100].replace("\n", "")
                        content_str += f"[ğŸµ éŸ³é¢‘ç»“æ„å‰100å­—: {raw}...]"
                print(f"{role}ï¼š{content_str}")
            else:
                print(f"{role}ï¼š{content}")

        # è¾“å…¥æ–‡æœ¬å†…å®¹
        user_text = input("\nè¯·è¾“å…¥æ–‡æœ¬å†…å®¹ï¼ˆexit é€€å‡ºï¼‰ï¼š").strip()
        if user_text.lower() == "exit":
            break

        content_list = [{"type": "text", "text": user_text}]

        # æ˜¯å¦å½•éŸ³
        use_recording = input("æ˜¯å¦è¿›è¡Œå½•éŸ³ï¼Ÿ(y/N)ï¼š").strip().lower()
        if use_recording == "y":
            audio_path = record_audio()
            audio_data_url = file_to_data_url(audio_path)
            content_list.append({
                "type": "audio_url",
                "audio_url": {"url": audio_data_url}
            })
        else:
            audio_path = input("è¯·è¾“å…¥éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆç•™ç©ºè·³è¿‡ï¼Œexit é€€å‡ºï¼‰ï¼š").strip()
            if audio_path.lower() == "exit":
                return
            if audio_path:
                if os.path.exists(audio_path):
                    audio_data_url = file_to_data_url(audio_path)
                    content_list.append({
                        "type": "audio_url",
                        "audio_url": {"url": audio_data_url}
                    })
                else:
                    print("âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡æœ¬è½®ã€‚")
                    continue


        # åŠ å…¥å¯¹è¯å†…å®¹
        messages.append({
            "role": "user",
            "content": content_list
        })
        # æ¯è½®å¯åŠ¨æ–°çš„æ‰“æ–­ç›‘å¬å™¨çº¿ç¨‹
        stop_event.clear()
        t_interrupt = threading.Thread(target=interrupt_listener)
        t_interrupt.start()

        # è¯·æ±‚å“åº”
        t1 = time.time()
        response = client.chat.completions.create(
            model="/workspace/minicpm",
            messages=messages,
            extra_body={
                "stop_token_ids": [151645, 151643],
                "temperature": 0.7,
                "top_p": 0.7
            },
            max_tokens=1024,
            stream=True
        )

        # è¾“å‡ºå“åº”
        first_token_time = None
        full_reply = ""

        for chunk in response:
            if stop_event.is_set():
                break
            if chunk.choices[0].delta and chunk.choices[0].delta.content:
                if first_token_time is None:
                    first_token_time = time.time()
                    print(f"\nâ±ï¸ é¦–ä¸ªå“åº”ç”¨æ—¶: {first_token_time - t1:.3f} ç§’\n")
                content_piece = chunk.choices[0].delta.content
                print(content_piece, end="", flush=True)
                full_reply += content_piece

        print("\n")
        
        # æ·»åŠ ï¼šç»“æŸç›‘å¬çº¿ç¨‹
        stop_event.set()
        t_interrupt.join()

        messages.append({
            "role": "assistant",
            "content": full_reply
        })

        # âœ… æ‰“å°å½“å‰å¯¹è¯å ç”¨çš„ token æ•°é‡
        token_count = count_tokens(messages, model="gpt-3.5-turbo")
        print(f"ğŸ§® å½“å‰æ€» token æ•°: {1.6 * token_count:.1f} tokens (ç²—ç•¥ä¼°ç®—)")

        # ä¿å­˜å¯¹è¯å†å²
        if conversation_file is None:
            conversation_file = save_conversation_history(messages)
        else:
            save_conversation_history(messages, conversation_file)

        round_count += 1
        stop_event.clear()


# å¯åŠ¨çº¿ç¨‹
t_stream = threading.Thread(target=run_minicpm_stream)
# t_interrupt = threading.Thread(target=interrupt_listener)

t_stream.start()
# t_interrupt.start()

t_stream.join()
stop_event.set()  # ä¿è¯ç›‘å¬çº¿ç¨‹èƒ½é€€å‡º
